{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a176d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import pygame\n",
    "import random\n",
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "\n",
    "\n",
    "width_global = 20\n",
    "height_global = 20\n",
    "\n",
    "class CrossyRoadEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": 12}\n",
    "\n",
    "    def __init__(self, render_mode=\"human\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.width = width_global\n",
    "        self.height = height_global\n",
    "        self.max_steps = self.width * self.height\n",
    "        self.render_mode = render_mode\n",
    "        \n",
    "        self.observation_space = spaces.Box(low=0, high=4, shape=(self.height * self.width,), dtype=np.int32)\n",
    "        self.action_space = spaces.Discrete(5)\n",
    "\n",
    "        self.success_count = 0\n",
    "        self.last_positions = []\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            pygame.init()\n",
    "            self.screen = pygame.display.set_mode((self.width * 40, self.height * 40))\n",
    "            self.clock = pygame.time.Clock()\n",
    "            self.font = pygame.font.SysFont(None, 24)\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, _ = gym.utils.seeding.np_random(seed)\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    def _get_obs(self):\n",
    "        grid = np.zeros((self.height, self.width), dtype=np.int32)\n",
    "        grid[self.agent_pos[1], self.agent_pos[0]] = 1\n",
    "        for rock in self.rocks:\n",
    "            grid[rock[1], rock[0]] = 2\n",
    "        for row in self.car_rows:\n",
    "            grid[row, :] = 4\n",
    "        for car in self.cars:\n",
    "            grid[car[1], car[0]] = 3\n",
    "        return grid.flatten()\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.seed(seed)\n",
    "\n",
    "        self.agent_pos = [self.width // 2, self.height - 1]\n",
    "        self.done = False\n",
    "        self.score = 0\n",
    "        self.steps = 0\n",
    "        self.last_positions = []\n",
    "\n",
    "        self.rocks = []\n",
    "        self.cars = []\n",
    "        self.car_rows = []\n",
    "        self.car_directions = {}\n",
    "\n",
    "        self.passed_top_bonus = False\n",
    "\n",
    "        forbidden_rows = [0, self.height - 1, self.height - 2]\n",
    "\n",
    "        rocks_count = int(np.random.randint(0.03 * self.width * self.height, 0.04 * self.width * self.height))\n",
    "        attempts = 0\n",
    "        while len(self.rocks) < rocks_count and attempts < 500:\n",
    "            rx = random.randint(1, self.width - 2)\n",
    "            ry = random.randint(1, self.height - 3)\n",
    "            if ry not in forbidden_rows and [rx, ry] not in self.rocks and [rx, ry] != self.agent_pos:\n",
    "                self.rocks.append([rx, ry])\n",
    "            attempts += 1\n",
    "\n",
    "        potential_car_rows = [y for y in range(1, self.height - 2) if y not in forbidden_rows and y not in [r[1] for r in self.rocks]]\n",
    "        random.shuffle(potential_car_rows)\n",
    "        self.car_rows = potential_car_rows[:3]\n",
    "\n",
    "        for row in self.car_rows:\n",
    "            self.car_directions[row] = random.choice([\"left\", \"right\"])\n",
    "            for _ in range(random.randint(1, 2)):\n",
    "                cx = random.randint(0, self.width - 1)\n",
    "                self.cars.append([cx, row])\n",
    "\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.done:\n",
    "            return self._get_obs(), 0, True, False, {\"success_count\": self.success_count}\n",
    "    \n",
    "        reward = 0.0\n",
    "        self.steps += 1\n",
    "    \n",
    "        x, y = self.agent_pos\n",
    "        new_x, new_y = x, y\n",
    "    \n",
    "        if action == 0 and y > 0:\n",
    "            new_y -= 1\n",
    "        elif action == 1 and y < self.height - 1:\n",
    "            new_y += 1\n",
    "        elif action == 2 and x > 0:\n",
    "            new_x -= 1\n",
    "        elif action == 3 and x < self.width - 1:\n",
    "            new_x += 1\n",
    "        elif action == 4:\n",
    "            reward -= 0.05 \n",
    "    \n",
    "        if [new_x, new_y] in self.rocks:\n",
    "            reward -= 0.2\n",
    "        else:\n",
    "            self.agent_pos = [new_x, new_y]\n",
    "    \n",
    "        new_cars = []\n",
    "        for x, y in self.cars:\n",
    "            if self.car_directions[y] == \"left\":\n",
    "                x = (x - 1) % self.width\n",
    "            else:\n",
    "                x = (x + 1) % self.width\n",
    "            new_cars.append([x, y])\n",
    "        self.cars = new_cars\n",
    "    \n",
    "        if self.agent_pos in self.cars:\n",
    "            reward -= 0.5  \n",
    "            self.done = True\n",
    "            return self._get_obs(), reward, self.done, False, {\"success_count\": self.success_count}\n",
    "    \n",
    "        if self.agent_pos[1] > y:\n",
    "            reward -= 0.3  \n",
    "        elif self.agent_pos[1] < y:\n",
    "            reward += 0.3  \n",
    "        \n",
    "        if not self.passed_top_bonus and self.agent_pos[1] <= int(0.2 * self.height):\n",
    "            reward += 2.0\n",
    "            self.passed_top_bonus = True\n",
    "\n",
    " \n",
    "    \n",
    "        if self.agent_pos[1] in [15, 10, 5]:\n",
    "            reward += 1.0\n",
    "    \n",
    "        self.last_positions.append(tuple(self.agent_pos))\n",
    "        if len(self.last_positions) > 10:\n",
    "            self.last_positions.pop(0)\n",
    "            if all(pos == tuple(self.agent_pos) for pos in self.last_positions):\n",
    "                reward -= 0.5\n",
    "    \n",
    "        if self.agent_pos[1] == 0:\n",
    "            reward += 10.0\n",
    "            self.done = True\n",
    "            self.success_count += 1\n",
    "        elif self.agent_pos[1] == self.height // 2:\n",
    "            reward += 5.0\n",
    "    \n",
    "        if self.steps >= self.max_steps:\n",
    "            self.done = True\n",
    "            \n",
    "\n",
    "        return self._get_obs(), reward, self.done, False, {\"success_count\": self.success_count}\n",
    "\n",
    "\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode != \"human\":\n",
    "            return\n",
    "\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "                exit()\n",
    "\n",
    "        self.screen.fill((170, 220, 60))\n",
    "\n",
    "        for row in self.car_rows:\n",
    "            for x in range(self.width):\n",
    "                pygame.draw.rect(self.screen, (50, 50, 50), (x * 40, row * 40, 40, 40))\n",
    "\n",
    "        for rock in self.rocks:\n",
    "            pygame.draw.rect(self.screen, (100, 100, 100), (rock[0] * 40, rock[1] * 40, 40, 40))\n",
    "\n",
    "        for car in self.cars:\n",
    "            pygame.draw.rect(self.screen, (255, 0, 0), (car[0] * 40, car[1] * 40, 40, 40))\n",
    "\n",
    "        pygame.draw.circle(self.screen, (255, 200, 0),\n",
    "                           (self.agent_pos[0] * 40 + 20, self.agent_pos[1] * 40 + 20), 20)\n",
    "\n",
    "        text = self.font.render(f\"Steps: {self.steps}  Successes: {self.success_count}\", True, (0, 0, 0))\n",
    "        self.screen.blit(text, (10, 10))\n",
    "\n",
    "        pygame.display.flip()\n",
    "        self.clock.tick(self.metadata[\"render_fps\"])\n",
    "\n",
    "    def close(self):\n",
    "        if self.render_mode == \"human\":\n",
    "            pygame.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f90ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"models/best_model\", exist_ok=True)\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "def make_env():\n",
    "    env = CrossyRoadEnv(render_mode=None)\n",
    "    return Monitor(env, filename=os.path.join(\"logs\", \"monitor.csv\"))\n",
    "\n",
    "train_env = DummyVecEnv([make_env])\n",
    "eval_env = DummyVecEnv([make_env])\n",
    "\n",
    "check_env(CrossyRoadEnv(render_mode=None), warn=True)\n",
    "\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    train_env,\n",
    "    verbose=1,\n",
    "    n_steps=2048,\n",
    "    batch_size=64,\n",
    "    learning_rate=2.5e-4,\n",
    "    gamma=0.99,\n",
    "    device=\"cpu\"\n",
    ")\n",
    "\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=\"./models/best_model\",\n",
    "    log_path=\"./logs\",\n",
    "    eval_freq=100_000,\n",
    "    n_eval_episodes=10,\n",
    "    deterministic=True,\n",
    "    render=False\n",
    ")\n",
    "\n",
    "model.learn(total_timesteps=1_000_000, callback=eval_callback)\n",
    "\n",
    "model.save(\"models/crossy_ppo\")\n",
    "\n",
    "print(\"✅ Trening zakończony. Model końcowy oraz najlepszy model zapisane.\")\n",
    "\n",
    "monitor_file = os.path.join(\"logs\", \"monitor.csv\")\n",
    "df = pd.read_csv(monitor_file, skiprows=1)\n",
    "\n",
    "df[\"timestep\"] = df[\"l\"].cumsum()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df[\"timestep\"], df[\"r\"], label=\"Reward per episode\")\n",
    "plt.xlabel(\"Timesteps\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Postęp treningu agenta PPO\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"logs/training_plot.png\")  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3574e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CrossyRoadEnv(render_mode=None)\n",
    "model = PPO.load(\"models/best_model/best_model\", device=\"cpu\")\n",
    "\n",
    "timeout_seconds = 24\n",
    "all_successes = 0\n",
    "all_episodes = 0\n",
    "tests = 5\n",
    "\n",
    "for i in range(tests):\n",
    "\n",
    "    success_count = 0\n",
    "    total_episodes = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    while (time.time() - start_time) < timeout_seconds:\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs)\n",
    "            action = int(action) \n",
    "            obs, reward, done, _, _ = env.step(action)\n",
    "            env.render()\n",
    "\n",
    "            if done :\n",
    "                total_episodes += 1\n",
    "                if  env.agent_pos[1] == 0:\n",
    "                    success_count += 1\n",
    "            \n",
    "\n",
    "    print(f\"✔️ Test nr {i+1} zakończony. Procent sukcesów: {(success_count / total_episodes) * 100:.2f}%\")\n",
    "    all_successes += success_count\n",
    "    all_episodes += total_episodes\n",
    "\n",
    "print(f\"Łączna liczba sukcesów we wszystkich testach: {all_successes}\")\n",
    "print(f\"Średnia liczba sukcesów na test: {all_successes / tests:.2f}\")\n",
    "print(f\"Średni procent sukcesów: {(all_successes / all_episodes) * 100:.2f}%\")\n",
    "\n",
    "\n",
    "env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
